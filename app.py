#!/usr/bin/env python
# -*- coding: utf-8 -*-
import streamlit as st
from PIL import Image
import os
import sys
import tempfile
import requests
from io import BytesIO
from core.config import PROJECT_ROOT
import re

sys.path.append(PROJECT_ROOT)
TEXT_STORE_PATH = os.path.join(PROJECT_ROOT, "data", "vector", "text")
IMAGE_STORE_PATH = os.path.join(PROJECT_ROOT, "data", "vector", "img")

from core.Multimodel_LLM import final_chat
from core.utils import ReadFiles
from core.LLM import ImageChat

# streamlit run app.py

# --- Streamlité…ç½® ---
st.set_page_config(layout="wide", page_icon="ğŸ¥")
st.markdown("""
<style>
    .fixed-input { position: fixed; bottom: 0; left: 0; right: 0; background-color: white; padding: 1rem; box-shadow: 0 -2px 10px rgba(0,0,0,0.1); z-index: 999; }
    .block-container { padding-bottom: 8rem; }
    .chat-box { padding: 1rem; border-radius: 10px; background-color: #f1f3f4; margin-bottom: 1rem; }
    .generated-image { border: 1px solid #e0e0e0; border-radius: 10px; margin: 1rem 0; }
    .sidebar-history-item {padding: 0.5rem;margin-bottom: 0.5rem;border-radius: 10px;background-color: #f7f9fa;border: 1px solid #f7f9fa;}
</style>
""", unsafe_allow_html=True)

# --- åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ ---
if "current_chat" not in st.session_state:
    st.session_state.current_chat = []
if "chat_histories" not in st.session_state:
    st.session_state.chat_histories = {}
if "selected_history" not in st.session_state:
    st.session_state.selected_history = None
if "chatbot" not in st.session_state:
    st.session_state.chatbot = None

# --- å·¥å…·å‡½æ•° ---
@st.cache_resource
def init_chatbot(model_name="glm-4-flash", temperature=0.3, threshold=0.5):
    return final_chat(
        TEXT_STORE_PATH,
        IMAGE_STORE_PATH,
        model_name=model_name,
        temperature=temperature,
        threshold=threshold,
        api_key=st.session_state.get("api_key", "")
    )

# --- é¡µé¢æ ‡é¢˜ ---
st.title("ğŸ¥ åŒ»ç–—æ´å‡€å®¤æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
st.subheader("æä¾›åŒ»ç–—æ´å‡€å®¤è®¾è®¡ã€æ ‡å‡†ã€æ“ä½œè§„èŒƒç­‰å…¨æ–¹ä½çŸ¥è¯†æœåŠ¡")

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»Ÿé…ç½®")
    model_choice = st.selectbox(
        "é€‰æ‹©å¤§æ¨¡å‹å¼•æ“",
        ["glm-4-flash", "glm-z1-air", "glm-z1-airx", "glm-4-flash-250414", "glm-4-air-250414", "glm-4-plus", "glm-4v",
         "cogview-4-250304"],
        index=0
    )
    temperature = st.slider("æ¨¡å‹æ¸©åº¦ç³»æ•° (0-1)", 0.0, 1.0, 0.3)
    threshold = st.slider("å›¾ç‰‡åŒ¹é…é˜ˆå€¼ (0-1)", 0.0, 1.0, 0.5)

    st.markdown("---")
    st.subheader("ğŸ”‘ API Key é…ç½®")
    api_key = st.text_input("è¯·è¾“å…¥æ‚¨çš„ æ™ºè°± BigModel API Key", type="password", value="")
    st.session_state.api_key = api_key

    st.markdown("---")
    st.subheader("ğŸ“‚ å†å²å¯¹è¯")
    for title in list(st.session_state.chat_histories.keys()):
        with st.container():
            hist_cols = st.columns([5, 1])
            fixed_title = title[:9]
            with hist_cols[0]:
                if st.button(fixed_title, key=f"load_{title}", use_container_width=True):
                    st.session_state.current_chat = st.session_state.chat_histories[title].copy()
                    st.session_state.selected_history = title
                    st.rerun()
            with hist_cols[1]:
                if st.button("âŒ", key=f"delete_{title}", use_container_width=True):
                    del st.session_state.chat_histories[title]
                    if st.session_state.selected_history == title:
                        st.session_state.selected_history = None
                        st.session_state.current_chat = []
                    st.rerun()

    st.markdown("---")
    if st.button("ğŸ†• å¼€å¯æ–°ä¼šè¯"):
        if st.session_state.current_chat:
            first_question = st.session_state.current_chat[0]['question']
            st.session_state.chat_histories[first_question] = st.session_state.current_chat.copy()
        st.session_state.current_chat = []
        st.session_state.selected_history = None
        st.session_state.uploaded_chunks = []
        if "image_content" in st.session_state:
            del st.session_state.image_content
        st.rerun()

# åˆå§‹åŒ–å›¾ç‰‡å¯¹è¯æ¨¡å‹
img_chat = ImageChat(api_key=st.session_state.get("api_key", ""))

# --- æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ ---
with st.expander("ğŸ“ ä¸Šä¼ è¾…åŠ©èµ„æ–™", expanded=False):
    uploaded_file = st.file_uploader("æ”¯æŒPDF/æ–‡æœ¬/å›¾ç‰‡æ ¼å¼", type=["pdf", "txt", "md", "png", "jpg", "jpeg"])
    if uploaded_file:
        with st.spinner("ğŸ” è§£ææ–‡ä»¶ä¸­..."):
            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}")
            tmp.write(uploaded_file.read())
            tmp.close()
            try:
                if uploaded_file.type == "application/pdf":
                    raw_text = ReadFiles.read_pdf(tmp.name)
                elif uploaded_file.type == "text/plain":
                    raw_text = ReadFiles.read_text(tmp.name)
                elif uploaded_file.type == "text/markdown":
                    raw_text = ReadFiles.read_markdown(tmp.name)
                else:
                    raw_text = img_chat.generate_response(tmp.name)
                    st.session_state.image_content = raw_text
                if raw_text:
                    chunks = ReadFiles.get_chunk2(raw_text)
                    st.session_state.uploaded_chunks = chunks
                    st.success(f"âœ… æˆåŠŸæå– {len(chunks)} ä¸ªçŸ¥è¯†ç‰‡æ®µ")
            except Exception as e:
                st.error(f"æ–‡ä»¶è§£æå¤±è´¥: {e}")

# --- æ¸²æŸ“å½“å‰èŠå¤©è®°å½• ---
for idx, entry in enumerate(st.session_state.current_chat):
    st.markdown(f"**ğŸ™‹ ç”¨æˆ·æé—® {idx + 1}:** {entry['question']}")

    #  å›¾ç‰‡å›ç­”
    if entry.get("answer_type") == "image":
        img_path = entry.get("answer_image_path", entry['answer'])
        try:
            if img_path.startswith("http"):
                st.image(img_path, caption="AI ç”Ÿæˆå›¾ç‰‡", use_container_width=True)
            elif os.path.exists(img_path):
                st.image(Image.open(img_path), caption="AI ç”Ÿæˆå›¾ç‰‡", use_container_width=True)
            else:
                st.error("æ— æ³•åŠ è½½å›¾ç‰‡èµ„æº")
        except Exception as e:
            st.error(f"å›¾ç‰‡åŠ è½½å¤±è´¥: {str(e)}")

    else:
        #  æ–‡æœ¬å›ç­”
        answer = entry['answer']
        st.write(f"<div class='chat-box'>ğŸ¤– ç³»ç»Ÿå›ç­”ï¼š{answer}</div>", unsafe_allow_html=True)

    # ç›¸å…³å‚è€ƒå›¾ç‰‡
    related = entry.get("related_images", [])
    if related:
        st.markdown("---")
        st.subheader("ğŸ“· ç›¸å…³å‚è€ƒå›¾ç‰‡")
        cols = st.columns(min(3, len(related)))
        for i, info in enumerate(related):
            with cols[i % 3]:
                try:
                    if os.path.exists(info["path"]):
                        st.image(Image.open(info["path"]),
                                 caption=f"æ¥æºï¼š{info['source']}",
                                 use_container_width=True)
                    else:
                        st.warning(f"å›¾ç‰‡æœªæ‰¾åˆ°ï¼š{os.path.basename(info['path'])}")
                except Exception as e:
                    st.error(f"å›¾ç‰‡åŠ è½½é”™è¯¯: {str(e)}")

# --- èŠå¤©è¾“å…¥æ¡† ---
with st.form("chat_input", clear_on_submit=True):
    q_col, btn_col = st.columns([5, 1])
    with q_col:
        question = st.text_area("è¾“å…¥æ‚¨çš„é—®é¢˜", height=100, placeholder="è¯·è¾“å…¥å…³äºåŒ»ç–—æ´å‡€å®¤çš„é—®é¢˜...",
                                label_visibility="collapsed")
    with btn_col:
        submitted = st.form_submit_button("ğŸš€ å‘é€")

# --- å¤„ç†æ–°é—®é¢˜ ---
if submitted:
    if not st.session_state.api_key.strip():
        st.warning("âš ï¸ è¯·å…ˆåœ¨å·¦ä¾§æ è¾“å…¥æœ‰æ•ˆçš„ API Keyï¼")
    elif not question.strip():
        st.warning("âš ï¸ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜åå†å‘é€ã€‚")
    else:
        if not st.session_state.chatbot or st.session_state.get("current_model") != model_choice:
            st.session_state.chatbot = init_chatbot(model_choice, temperature, threshold)
            st.session_state.current_model = model_choice

        with st.spinner("ğŸ” æ£€ç´¢çŸ¥è¯†åº“å¹¶ç”Ÿæˆå›ç­”..."):
            extra = st.session_state.get("uploaded_chunks", [])
            img_ctx = [st.session_state.get("image_content", "")] if 'image_content' in st.session_state else []
            history_ctx = [f"Q: {item['question']}\nA: {item['answer']}" for item in st.session_state.current_chat]

            raw_answer, is_image = st.session_state.chatbot.Chat_GLM(
                "\n".join(history_ctx + [question]),
                additional_context=extra + img_ctx
            )

            related_images = []
            for p in st.session_state.chatbot.get_img_path() or []:
                print(os.path.dirname(p))
                if os.path.exists(p):
                    related_images.append({
                        "path": p,
                        "source": os.path.basename(os.path.dirname(p))
                    })

            entry = {
                "question": question,
                "related_images": related_images,
                "answer": raw_answer,
                "answer_type": "image" if is_image else "text"
            }

            if is_image:
                try:
                    if raw_answer.startswith("http"):
                        response = requests.get(raw_answer)
                        img = Image.open(BytesIO(response.content))
                        tmp_path = os.path.join(tempfile.gettempdir(),
                                                f"generated_{len(st.session_state.current_chat)}.png")
                        img.save(tmp_path)
                        entry["answer_image_path"] = tmp_path
                except Exception as e:
                    st.error(f"å›¾ç‰‡ä¿å­˜å¤±è´¥: {str(e)}")
                    entry["answer_type"] = "text"
                    entry["answer"] = "å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•"

            st.session_state.current_chat.append(entry)
            st.rerun()